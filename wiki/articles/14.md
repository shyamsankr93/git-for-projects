The crossed dataset has one line for each stock and each day and contains the aggregated news and the anomaly flagged associated. The goal therefore is to predict the anomaly flag using information contained in the aggregated news. It can happen that no news was published for a stock on a given day, this data point is discarded.

# Feature Handling

The aggregated news titles are stemmed, normalized, cleared from stop words and handled using count vectorization. The number of different words used in these titles is not that large as many are redundant so count vectorization can run without any problem. Furthermore, this way models can be interpretable as each word's presence has given weight in the model.

# Logistic Regression

A logistic regression is then estimated to link the news with the two-class anomaly variable. Logistic regression has the advantages of being simple, robust and to provide interpretable results. The classes are highly unbalanced (about 3% anomalies), so to improve the performance of the model, observations are weighted by the inverse of the class cardinal.

# Scoring

Once learned, the model outputs for each observation a probability of being an anomaly and the optimization has defined a threshold which enables it to categorize observations into the anomaly category or not when the probability is over this threshold.

Here our goal in the end is not to predict if there is an anomaly on a stock, rather to score each stock and rank them according to their estimated risk permitting the user to focus his attention on the stocks most likely to show anomalous behaviours.

# Follow Up

In this model, only news aggregated on the current day are used to predict an anomaly. We could consider using past news and stock returns to extract patterns explaining the anomaly presence. Furthermore, other data sources could be added and combined to enrich the models, like ESG data sources.